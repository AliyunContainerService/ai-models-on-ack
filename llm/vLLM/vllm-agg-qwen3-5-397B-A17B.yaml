apiVersion: workloads.x-k8s.io/v1alpha1
kind: RoleBasedGroup
metadata:
  name: qwen3-5-vllm-agg
spec:
  roles:
    - name: server
      replicas: 1
      template:
        metadata:
        spec:
          containers:
            - name: engine
              image: ac2-mirror-registry.cn-hangzhou.cr.aliyuncs.com/evaluate/vllm-openai:nightly-d00df624f313a6a5a7a6245b71448b068b080cd7
              command:
                - vllm
                - serve
                - /models/Qwen3.5-397B-A17B
                - --served-model-name
                - Qwen3.5-397B-A17B
                - --port
                - "8000"
                - --tensor-parallel-size
                - "8"
              ports:
                - containerPort: 8000
                  name: http
              readinessProbe:
                initialDelaySeconds: 30
                periodSeconds: 10
                tcpSocket:
                  port: 8000
              resources:
                limits:
                  nvidia.com/gpu: "8"
                requests:
                  nvidia.com/gpu: "8"
              volumeMounts:
                - mountPath: /models/Qwen3.5-397B-A17B
                  name: model
                - mountPath: /dev/shm
                  name: dshm
          volumes:
          - name: model
            persistentVolumeClaim:
              claimName: qwen3-5
          - name: dshm
            emptyDir:
              medium: Memory
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: qwen3-5-vllm-agg
  name: qwen3-5-vllm-agg
  namespace: default
spec:
  ports:
    - name: http
      port: 8000
      protocol: TCP
      targetPort: 8000
  selector:
    rolebasedgroup.workloads.x-k8s.io/name: qwen3-5-vllm-agg
    rolebasedgroup.workloads.x-k8s.io/role: server
  type: ClusterIP
